<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhenglun Kong</title>
  
  <meta name="author" content="Zhenglun Kong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">

  <style type="text/css">

    .school-logo {
      width: 6%;
      float: left;
    }

    .school-text {
      margin-left: 10%;
      width: 60%;
    }
  </style>


</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhenglun Kong</name>
              </p>
              <p>I am a final-year PhD student at Northeastern University, supervised by Prof. <a href="https://web.northeastern.edu/yanzhiwang/#_ga=2.59245165.1964588443.1663640196-2055581220.1641240155">Yanzhi Wang</a>.  I received my master degree from Northeastern University in 2019 and B.E. degree from Huazhong University of Science and Technology (HUST), China, in 2017. My current research is on machine learning, model compression, and computer vision.
              </p>
              <p style="text-align:center">
                <a href="mailto:kong.zhe@northeastern.edu">Email</a> &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/1JpCkiPb-UJ4ATE9N2J2eDWBFXWW-Hnk7/view?usp=sharing">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=XYa4NVYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ZLKong/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/zhenglun-kong-35b527150/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/WechatIMG9165.jpeg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/WechatIMG9165.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
              I am deeply invested in addressing the growing challenge posed by the extensive resource consumption of neural networks, which results in a significant carbon footprint, hinders academic research accessibility, and restricts the proliferation of AI benefits in emerging economies. My research is particularly focused on the following domains and methodologies: 
              <p>
            <ul>
           <li><p>
              Energy-Efficient Deep Learning:  Efficient training and inference, model compression, and efficient DNN design.
            </p>
            <li><p>
              General AI Landing: Algorithm-hardware co-design for mobile device and FPGA 
            </p>
            <li><p>
              Methodologies: Token/weight pruning, quantization, sparse training, data distillation, and latency-aware neural architecture search.
            </p>
            <li><p>
              Models: Large Language Models (GPT, LLaMA, BERT, and variants), Vision Models (Vision Transformer, DETR, ResNet, and variants).
            </p>
            <li><p> 
              Tasks & Applications: Image classification, 3D object detection for autonomous driving systems, medical image segmentation, and exploring the influence of generative AI in business.
            </p>

            </ul>
          </td>
        </tr>

        <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Experiences</heading>
                <p>
                <ul id="exp" style="list-style:none;">
                  <li style="margin-bottom: 20px;"> <img class="school-logo" src="images/northeastern_logo.png">
                    <div class="school-text"> Northeastern University, Sep 2019 - Present,<br />Research Assistant
                      <br /> Advisor: Prof. Yanzhi Wang
                    </div>
                  </li>
                  <li style="margin-bottom: 20px;"> <img class="school-logo" src="images/Microsoft_logo.png">
                    <div class="school-text">Microsoft, June 2022 - August 2022 <br />Research Intern
                     <br /> Mentor: Subhabrata Mukherjee  
                    </div>
                  <li style="margin-bottom: 20px;"> <img class="school-logo" src="images/Arm_logo_2017.png">
                    <div class="school-text">ARM, June 2021 - August 2021 <br />Research Intern
                     <br /> Mentors: Lingchuan Meng, Danny Loh
                    </div>
                  <li style="margin-bottom: 20px;"> <img class="school-logo" src="images/samsung.png">
                    <div class="school-text">Samsung Research America, October 2021 - December 2021 <br />Research Intern
                     <br /> Mentors: Avik Ray, Yilin Shen, Hongxia Jin
                    </div>
                  </li>
                </ul>
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Publications</heading> <br>
              <a href="https://scholar.google.com/citations?user=hwTuEX0AAAAJ&hl=en">Google Scholar</a>
              <font color="grey">for all publications</font>.
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TMLR.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Lightweight Vision Transformer Coarse-to-Fine Search via Latency Profiling</papertitle>
              </a>
              <br>
              <b>Zhenglun Kong*</b>, Dongkuan Xu, Zhengang Li, Peiyan Dong, Hao Tang, Yanzhi Wang, Subhabrata Mukherjee
              <br>
              <em><b>[TMLR]</b></em> <i>Transactions on Machine Learning Research</i>
              <br>
              <a href="https://openreview.net/pdf?id=sTdd0yCOZ2"><font color="red">PDF</font></a> / 
              <p></p>
              <p> We introduce a truly efficient, hardware-oriented approach for searching efficient vision transformer structure. This approach has been optimized to seamlessly adapt to the constraints of the target hardware and fulfill the specific speed requirements.</p>
            </td>
          </tr>
          <tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/Neurips2023.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>HotBEV: Hardware-oriented Transformer-based Multi-View 3D Detector for BEV Perception</papertitle>
              </a>
              <br>
              Peiyan Dong*, <b>Zhenglun Kong*</b>, Xin Meng, Pinrui Yu, Yanyue Xie, Yifan Gong, Geng Yuan, Fei Sun, Hao Tang, Yanzhi Wang
              <br>
              <em><b>[NeurIPS 2023]</b></em> <i>Advances in Neural Information Processing Systems</i>
              <br>
              <p></p>
              <p> We present a hardware-oriented transformer-based framework for 3D detection tasks, which achieves higher detection precision and remarkable speedup across high-end and low-end GPUs.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICML2023.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>SpeedDETR: Speed-aware Transformers for End-to-end Object Detection</papertitle>
              </a>
              <br>
              Peiyan Dong*, <b>Zhenglun Kong*</b>, Xin Meng, Peng Zhang, Hao Tang, Yanzhi Wang, Chih-Hsien Chou
              <br>
              <em><b>[ICML 2023]</b></em> <i>International Conference on Machine Learning</i>
              <br>
              <a href="https://openreview.net/pdf?id=5VdcSxrlTK"><font color="red">PDF</font></a> / 
              <a href="https://github.com/PeiyanFlying/SpeedDETR"><font color="red">Code</font></a>/
              <p></p>
              <p> We propose a novel speed-aware transformer for end-to-end object detectors, achieving high-speed inference on multiple devices.</p>
            </td>
          </tr>
          <tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ECCV2022.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>SPViT: Enabling Faster Vision Transformers via Latency-aware Soft Token Pruning</papertitle>
              </a>
              <br>
              <b>Zhenglun Kong*</b>, Peiyan Dong*, Xiaolong Ma, Xin Meng, Mengshu Sun, Wei Niu, Xuan Shen, Geng Yuan, Bin Ren, Minghai Qin, Hao Tang, Yanzhi Wang
              <br>
              <em><b>[ECCV 2022]</b></em> <i>European Conference on Computer Vision</i>
              <br>
              <a href="https://arxiv.org/pdf/2112.13890.pdf"><font color="red">PDF</font></a> / 
              <a href="https://github.com/PeiyanFlying/SPViT"><font color="red">Code</font></a>/
              <p></p>
              <p> We propose a dynamic, latency-aware soft token pruning framework for Vision Transformer.</p>
            </td>
          </tr>


          <tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/AAAI2023.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Peeling the Onion: Hierarchical Reduction of Data Redundancy for Efficient Vision Transformer Training</papertitle>
              </a>
              <br>
              <b>Zhenglun Kong*</b>, Haoyu Ma*, Geng Yuan, Mengshu Sun, Yanyue Xie, Peiyan Dong,  Yanzhi Wang, et al.
              <br>
              <em><b>[AAAI 2023]</b></em> <i>The Thirty-Seventh AAAI Conference on Artificial Intelligence</i>
              <br>
              <a href="https://arxiv.org/pdf/2211.10801.pdf"><font color="red">PDF</font></a> / 
              <a href="https://github.com/ZLKong/Tri-Level-ViT"><font color="red">Code</font></a>/
              <p></p>
              <p> In this work, we introduce sparsity into data and propose an end-to-end efficient training framework to accelerate ViT training and inference.  </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/EMNLP2020.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Efficient Transformer-based Large Scale Language Representations using Hardware-friendly Block Structured Pruning</papertitle>
              </a>
              <br>
              Bingbing Li*, <b>Zhenglun Kong*</b>, Tianyun Zhang, Ji Li, Zhengang Li, Hang Liu, Caiwen Ding
              <br>
              <em><b>[EMNLP 2020 Findings]</b></em> <i>Conference on Empirical Methods in Natural Language Processing</i>
              <br>
              <a href="https://browse.arxiv.org/pdf/2009.08065.pdf"><font color="red">PDF</font></a> / 
              <p></p>
              <p>  we propose an efficient transformer-based large-scale language representation using hardware-friendly block structure pruning. We incorporate the reweighted group Lasso into block-structured pruning for optimization.  </p>
            </td>
          </tr>

          </table>
      </td>
    </tr>
  </table>
</body>

</html>
